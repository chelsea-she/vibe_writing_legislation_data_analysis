{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "832f863e",
   "metadata": {},
   "source": [
    "### I. Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6bdb4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.9/site-packages (2.3.0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in ./.venv/lib/python3.9/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.9/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.9/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: plotly in ./.venv/lib/python3.9/site-packages (6.1.2)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in ./.venv/lib/python3.9/site-packages (from plotly) (1.42.1)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.9/site-packages (from plotly) (25.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nbformat in ./.venv/lib/python3.9/site-packages (5.10.4)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in ./.venv/lib/python3.9/site-packages (from nbformat) (2.21.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in ./.venv/lib/python3.9/site-packages (from nbformat) (4.24.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./.venv/lib/python3.9/site-packages (from nbformat) (5.8.1)\n",
      "Requirement already satisfied: traitlets>=5.1 in ./.venv/lib/python3.9/site-packages (from nbformat) (5.14.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./.venv/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.venv/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./.venv/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./.venv/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat) (0.25.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./.venv/lib/python3.9/site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.3.8)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in ./.venv/lib/python3.9/site-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat) (4.14.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nbformat in ./.venv/lib/python3.9/site-packages (5.10.4)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in ./.venv/lib/python3.9/site-packages (from nbformat) (2.21.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in ./.venv/lib/python3.9/site-packages (from nbformat) (4.24.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./.venv/lib/python3.9/site-packages (from nbformat) (5.8.1)\n",
      "Requirement already satisfied: traitlets>=5.1 in ./.venv/lib/python3.9/site-packages (from nbformat) (5.14.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./.venv/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.venv/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./.venv/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./.venv/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat) (0.25.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./.venv/lib/python3.9/site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.3.8)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in ./.venv/lib/python3.9/site-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat) (4.14.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: ace_tools_open in ./.venv/lib/python3.9/site-packages (0.1.0)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.9/site-packages (from ace_tools_open) (2.3.0)\n",
      "Requirement already satisfied: itables in ./.venv/lib/python3.9/site-packages (from ace_tools_open) (2.4.4)\n",
      "Requirement already satisfied: IPython in ./.venv/lib/python3.9/site-packages (from ace_tools_open) (8.18.1)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.9/site-packages (from IPython->ace_tools_open) (5.2.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.9/site-packages (from IPython->ace_tools_open) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./.venv/lib/python3.9/site-packages (from IPython->ace_tools_open) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.9/site-packages (from IPython->ace_tools_open) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.9/site-packages (from IPython->ace_tools_open) (2.19.1)\n",
      "Requirement already satisfied: stack-data in ./.venv/lib/python3.9/site-packages (from IPython->ace_tools_open) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5 in ./.venv/lib/python3.9/site-packages (from IPython->ace_tools_open) (5.14.3)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.9/site-packages (from IPython->ace_tools_open) (4.14.0)\n",
      "Requirement already satisfied: exceptiongroup in ./.venv/lib/python3.9/site-packages (from IPython->ace_tools_open) (1.3.0)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.9/site-packages (from IPython->ace_tools_open) (4.9.0)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.9/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->IPython->ace_tools_open) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.9/site-packages (from jedi>=0.16->IPython->ace_tools_open) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.9/site-packages (from pexpect>4.3->IPython->ace_tools_open) (0.7.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.9/site-packages (from itables->ace_tools_open) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.9/site-packages (from pandas->ace_tools_open) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.9/site-packages (from pandas->ace_tools_open) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.9/site-packages (from pandas->ace_tools_open) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->ace_tools_open) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.9/site-packages (from stack-data->IPython->ace_tools_open) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.9/site-packages (from stack-data->IPython->ace_tools_open) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.9/site-packages (from stack-data->IPython->ace_tools_open) (0.2.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install plotly\n",
    "%pip install nbformat\n",
    "import sys\n",
    "!{sys.executable} -m pip install nbformat --upgrade\n",
    "%pip install ace_tools_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0be59f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chelseashe/Thought_Toolkit/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logs successfully saved to: /Users/chelseashe/Thought_Toolkit/formal1_logs.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chelseashe/Thought_Toolkit/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n",
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "# Required packages: plotly, pandas\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "from collections import defaultdict\n",
    "import ace_tools_open as tools\n",
    "\n",
    "import level_2_learning_comparisons\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf98b676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# Make sure the file name is correct and in the same directory as the script\n",
    "with open(\"level_2_actions_per_session_semantic.json\") as f:\n",
    "    level_2_actions_per_session_semantic = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd009cc",
   "metadata": {},
   "source": [
    "### II Semantic Visualization - Correlation between semantic expansion per sentence text_insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "056e9818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting and helper functions\n",
    "def plot_semantic_expansion_sentence(writing_data, session_ids):\n",
    "    fig = make_subplots(\n",
    "        rows=len(session_ids),\n",
    "        cols=1,\n",
    "        subplot_titles=[f\"Session: {session_id}\" for session_id in session_ids],\n",
    "        vertical_spacing=0.15,\n",
    "    )\n",
    "    for idx, session_id in enumerate(session_ids, start=1):\n",
    "        if session_id not in writing_data:\n",
    "            print(f\"Warning: No data found for {session_id}\")\n",
    "            continue\n",
    "\n",
    "        session_actions = writing_data[session_id]\n",
    "        learning_data = []\n",
    "\n",
    "        total_actions = len(session_actions)\n",
    "        last_text_insert_actions = []\n",
    "        writing_progress = 0\n",
    "        for i, action in enumerate(session_actions):\n",
    "            if \"writing_type\" in action:\n",
    "                if action[\"writing_type\"] == \"backstage\":\n",
    "                    if action[\"level_1_action_type\"] == \"insert_text_human_ai_prompt\":\n",
    "                        learning_data.append(\n",
    "                            {\n",
    "                                \"writing_progress\": writing_progress,\n",
    "                                \"action_type\": action.get(\"action_type\", \"\"),\n",
    "                                \"level_1_action_type\": \"human_insert_backstage\",\n",
    "                                \"semantic_expanstion\": action[\"semantic_expansion\"]\n",
    "                            }\n",
    "                        )\n",
    "                        writing_progress += 1\n",
    "                    elif action[\"level_1_action_type\"] == \"present_suggestion\":\n",
    "                        learning_data.append(\n",
    "                            {\n",
    "                                \"writing_progress\": writing_progress,\n",
    "                                \"action_type\": action.get(\"action_type\", \"\"),\n",
    "                                \"level_1_action_type\": \"ai_suggest_backstage\",\n",
    "                                \"semantic_expanstion\": action[\"semantic_expansion\"],\n",
    "                            }\n",
    "                        )\n",
    "                        writing_progress += 1\n",
    "                    # NEED TO IMPLEMENT THESE LATER\n",
    "                    # elif action[\"level_1_action_type\"] == \"delete_text\"\n",
    "                    # elif action[\"level_1_action_type\"] == \"human_edit_ai\"\n",
    "                elif action[\"writing_type\"] == \"frontstage\":\n",
    "                    if action[\"level_1_action_type\"] == \"insert_text_human\" and (not \"level_2_action_type\" in action or action[\"level_2_action_type\"] != \"human_edit_ai\"):\n",
    "                        for sentence in action[\"action_modified_sentences\"]:\n",
    "                            learning_data.append(\n",
    "                                {\n",
    "                                    \"writing_progress\": writing_progress,\n",
    "                                    \"action_type\": action.get(\"action_type\", \"\"),\n",
    "                                    \"level_1_action_type\": \"human_insert_frontstage\",\n",
    "                                    \"semantic_expansion\": action[\n",
    "                                        \"semantic_expansion_info\"\n",
    "                                    ][sentence],\n",
    "                                }\n",
    "                            )\n",
    "                            writing_progress += 1\n",
    "                            added = False\n",
    "                    elif action[\"level_2_action_type\"] == \"move_frontstage\":\n",
    "                        learning_data.append(\n",
    "                            {\n",
    "                                \"writing_progress\": writing_progress,\n",
    "                                \"action_type\": action.get(\"action_type\", \"\"),\n",
    "                                \"level_1_action_type\": \"ai_insert_moved_to_frontstage\",\n",
    "                                \"semantic_expansion\": action[\"semantic_expansion_info\"][\n",
    "                                    sentence\n",
    "                                ],\n",
    "                            }\n",
    "                        )\n",
    "                        writing_progress += 1\n",
    "                    elif action[\"level_1_action_type\"] == \"delete_text\":\n",
    "                        learning_data.append(\n",
    "                            {\n",
    "                                \"writing_progress\": writing_progress,\n",
    "                                \"action_type\": action.get(\"action_type\", \"\"),\n",
    "                                \"level_1_action_type\": \"human_delete_frontstage\",\n",
    "                                \"semantic_expansion\": action[\"semantic_expansion_info\"][\n",
    "                                    sentence\n",
    "                                ],\n",
    "                            }\n",
    "                        )\n",
    "                        writing_progress += 1\n",
    "                    elif \"level_2_action_type\" in action and action[\"level_2_action_type\"] == \"human_edit_ai\":\n",
    "                        learning_data.append(\n",
    "                            {\n",
    "                                \"writing_progress\": writing_progress,\n",
    "                                \"action_type\": action.get(\"action_type\", \"\"),\n",
    "                                \"level_1_action_type\": \"human_insert_edit_frontstage\",\n",
    "                                \"semantic_expansion\": action[\"semantic_expansion_info\"][\n",
    "                                    sentence\n",
    "                                ],\n",
    "                            }\n",
    "                        )\n",
    "                        writing_progress += 1\n",
    "\n",
    "        learning_data = sorted(learning_data, key=lambda x: x[\"writing_progress\"])\n",
    "        # print(learning_data)\n",
    "\n",
    "        if not learning_data:\n",
    "            print(f\"Warning: No data found for {session_id}\")\n",
    "            continue\n",
    "\n",
    "        data_df = pd.DataFrame(learning_data)\n",
    "\n",
    "        # Graph individual cognitive measures\n",
    "        y_max = 0.0\n",
    "        aggregate_score = 0.0\n",
    "        backstage_addition = 0.0\n",
    "        aggregate_data = []\n",
    "        for learning_index, action in enumerate(learning_data):\n",
    "            details = {\n",
    "                \"writing_progress\": action[\"writing_progress\"],\n",
    "                \"level_1_action_type\": action[\"level_1_action_type\"],\n",
    "                \"aggregate_semantic_expansion_frontend\": aggregate_score,\n",
    "                \"increment_semantic_expansion\": action[\"semantic_expansion\"],\n",
    "            }\n",
    "            if \"backstage\" in action[\"level_1_action_type\"]:\n",
    "                if learning_index>0 and learning_data[learning_index-1]:\n",
    "                    details[\"aggregate_semantic_expansion_frontend\"] += backstage_addition\n",
    "                backstage_addition += action[\"semantic_expansion\"]\n",
    "            if \"frontstage\" in action[\"level_1_action_type\"] and learning_index > 0 and learning_data[learning_index - 1]:\n",
    "                backstage_addition = 0.0\n",
    "\n",
    "            aggregate_data.append(details)\n",
    "            if aggregate_score > y_max:\n",
    "                y_max = aggregate_score\n",
    "        aggregate_df = pd.DataFrame(aggregate_data)\n",
    "        print(f\"{session_id}\")\n",
    "\n",
    "        colors = {\n",
    "            \"human_insert_backstage\": \"#64B5F6\",\n",
    "            \"ai_suggest_backstage\": \"#ff8fab\",\n",
    "            \"human_insert_frontstage\": \"#023e8a\",\n",
    "            \"ai_insert_moved_to_frontstage\": \"#c1121f\",\n",
    "            \"human_delete_frontstage\": \"#9d4edd\",\n",
    "            \"human_insert_edit_frontstage\": \"#5a189a\",\n",
    "        }\n",
    "\n",
    "        for action_type in colors.keys():\n",
    "            actions = [\n",
    "                action\n",
    "                for action in aggregate_data\n",
    "                if action.get(\"level_1_action_type\") == action_type\n",
    "            ]\n",
    "            for action in actions:\n",
    "                x_0 = 0.0\n",
    "                if action[\"writing_progress\"] > 0:\n",
    "                    x_0 = action[\"writing_progress\"]\n",
    "                fig.add_shape(\n",
    "                    type=\"line\",\n",
    "                    x0=x_0,\n",
    "                    x1=action[\"writing_progress\"],\n",
    "                    y0=action[\"aggregate_semantic_expansion_frontend\"],\n",
    "                    y1=action[\"aggregate_semantic_expansion_frontend\"]+action[\"increment_semantic_expansion\"],\n",
    "                    yref=\"y\",  # Must match the y-axis of the graph\n",
    "                    line=dict(color=colors[action_type], width=2),\n",
    "                    row=idx,\n",
    "                    col=1,\n",
    "                )\n",
    "\n",
    "        if idx == 1:\n",
    "            for color, hex in colors.items():\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=[None],\n",
    "                        y=[None],\n",
    "                        mode=\"lines\",\n",
    "                        line=dict(color=hex, width=2),\n",
    "                        name=color,\n",
    "                        showlegend=True,\n",
    "                    ),\n",
    "                    row=1,\n",
    "                    col=1,\n",
    "                )\n",
    "\n",
    "    fig.update_layout(\n",
    "        plot_bgcolor=\"white\",\n",
    "        legend_title_font_color=\"rgba(0, 0, 0, 0)\",\n",
    "        height=300 * len(session_ids),\n",
    "        width=2400,\n",
    "        showlegend=True,\n",
    "        title={\n",
    "            \"text\": \"Semantic Expansion over Writing Sessions<br>\"\n",
    "            + '<span style=\"font-size: 12px;\">*Measuring how well humans are learning while writing with GenAI</span>',\n",
    "        },\n",
    "    )\n",
    "\n",
    "    fig.update_xaxes(\n",
    "        title=None,\n",
    "        range=[-1, data_df[\"writing_progress\"].max()+1],\n",
    "        mirror=False,\n",
    "        ticks=\"outside\",\n",
    "        showline=True,\n",
    "        linecolor=\"black\",\n",
    "        gridcolor=\"white\",\n",
    "    )\n",
    "\n",
    "    fig.update_xaxes(\n",
    "        title=\"Progress into the writing session\", row=len(session_ids), col=1\n",
    "    )\n",
    "\n",
    "    fig.update_yaxes(\n",
    "        title=\"Scores\",\n",
    "        mirror=False,\n",
    "        ticks=\"outside\",\n",
    "        showline=True,\n",
    "        linecolor=\"black\",\n",
    "        gridcolor=\"white\",\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d486f367",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'level_2_action_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Generate the plot\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m session_id \u001b[38;5;129;01min\u001b[39;00m session_ids:\n\u001b[0;32m---> 23\u001b[0m     fig \u001b[38;5;241m=\u001b[39m \u001b[43mplot_semantic_expansion_sentence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriting_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43msession_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 61\u001b[0m, in \u001b[0;36mplot_semantic_expansion_sentence\u001b[0;34m(writing_data, session_ids)\u001b[0m\n\u001b[1;32m     59\u001b[0m         writing_progress \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     60\u001b[0m         added \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43maction\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlevel_2_action_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmove_frontstage\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     62\u001b[0m     learning_data\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m     63\u001b[0m         {\n\u001b[1;32m     64\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwriting_progress\u001b[39m\u001b[38;5;124m\"\u001b[39m: writing_progress,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m         }\n\u001b[1;32m     71\u001b[0m     )\n\u001b[1;32m     72\u001b[0m     writing_progress \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'level_2_action_type'"
     ]
    }
   ],
   "source": [
    "writing_data = level_2_actions_per_session_semantic\n",
    "# Session IDs: An array of sessions you wish to plot.\n",
    "# Adjust as needed. Check session IDs in data exploration for options.\n",
    "session_ids = [\n",
    "    \"legislation_corporate_1\",\n",
    "    \"legislation_corporate_2\",\n",
    "    \"legislation_corporate_3\",\n",
    "    \"legislation_corporate_4\",\n",
    "    \"legislation_corporate_5\",\n",
    "    \"legislation_corporate_6\",\n",
    "    \"legislation_antitrust_1\",\n",
    "    \"legislation_antitrust_2\",\n",
    "    \"legislation_antitrust_3\",\n",
    "    \"legislation_antitrust_4\",\n",
    "    \"legislation_antitrust_5\",\n",
    "    \"legislation_antitrust_6\",\n",
    "    \"legislation_antitrust_7\",\n",
    "    \"legislation_antitrust_8\",\n",
    "]\n",
    "\n",
    "# Generate the plot\n",
    "for session_id in session_ids:\n",
    "    fig = plot_semantic_expansion_sentence(writing_data, [session_id])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
