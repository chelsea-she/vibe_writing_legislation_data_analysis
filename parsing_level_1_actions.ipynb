{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0ae5ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-Levenshtein in ./.venv/lib/python3.9/site-packages (0.27.1)\n",
      "Requirement already satisfied: Levenshtein==0.27.1 in ./.venv/lib/python3.9/site-packages (from python-Levenshtein) (0.27.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in ./.venv/lib/python3.9/site-packages (from Levenshtein==0.27.1->python-Levenshtein) (3.13.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2521c8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chelseashe/Thought_Toolkit/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logs successfully saved to: /Users/chelseashe/Thought_Toolkit/formal1_logs.json\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "import action_parser\n",
    "from extract_coauthor_raw_logs import jsonl_names\n",
    "\n",
    "import re\n",
    "import Levenshtein"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853b8c93",
   "metadata": {},
   "source": [
    "### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e93c0d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the current working directory\n",
    "script_dir = os.getcwd()\n",
    "\n",
    "# Get the raw log dataset\n",
    "file_path = os.path.join(script_dir, 'formal1_logs.json')\n",
    "\n",
    "# Feel free to uncomment the line below and start with a smaller sample (20 writing sessions) to reduce runtime\n",
    "# file_path = os.path.join(script_dir, 'small_logs_for_test.json')\n",
    "\n",
    "# Open and load the JSON file\n",
    "with open(file_path) as f:\n",
    "    logs_by_session = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90728f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fixed and loaded JSON successfully!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Load raw JSON-like data from file\n",
    "file_path = os.path.join(script_dir, '/content/testing_new_site.json')\n",
    "with open(file_path, 'r') as f:\n",
    "    raw_data = f.read()\n",
    "\"\"\"\n",
    "\n",
    "raw_data = logs_by_session\n",
    "\n",
    "\n",
    "def fix_all_arrays(raw_json_string):\n",
    "    def fix_array(match):\n",
    "        array_content = match.group(1)\n",
    "        # Add commas between objects: }{\n",
    "        fixed = re.sub(r'\\}\\s*\\{', '},\\n{', array_content.strip())\n",
    "        return f'[{fixed}]'\n",
    "\n",
    "    # Regex: match any array content following a key\n",
    "    fixed_json_string = re.sub(r'\\[\\s*({.*?})\\s*\\]', lambda m: fix_array(m), raw_json_string, flags=re.DOTALL)\n",
    "    return fixed_json_string\n",
    "\n",
    "\n",
    "# This regex looks for a pattern where a closing brace is immediately followed (with any whitespace) by an opening brace,\n",
    "# and inserts a comma between them.\n",
    "raw_data_str = json.dumps(logs_by_session)\n",
    "fixed_data = re.sub(r'(\\})\\s*(\\{)', r'\\1, \\2', raw_data_str)\n",
    "\n",
    "\n",
    "# Now try to load the fixed data as JSON.\n",
    "try:\n",
    "    logs_by_session = json.loads(fixed_data)\n",
    "    print(\"✅ Fixed and loaded JSON successfully!\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(\"❌ Failed to parse JSON:\", e)\n",
    "\n",
    "\n",
    "for test_user, events in logs_by_session.items():\n",
    "    if isinstance(events, list):\n",
    "       logs_by_session[test_user] = [\n",
    "            event for event in events if event.get(\"eventName\") != \"system-initialize\"\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbbb21a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_strings_similar_lev(str1, str2, max_differences=4):\n",
    "    distance = Levenshtein.distance(str1, str2)\n",
    "    return distance <= max_differences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc2a52d",
   "metadata": {},
   "source": [
    "### Parsing Raw Log JSON File into Structured Level 1 Actions\n",
    "\n",
    "This section processes raw logs and converts them into Level 1 actions using a analyzer. Each parsed action is enriched with a **level_1_action_type** key, which specifies the action type (e.g., `insert_text`, `delete_text`, `accept_suggestion`).\n",
    "\n",
    "**level_1_actions_per_session** is a dictionary where each session key maps to a list of parsed actions, organizing the output by session for streamlined analysis and further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49d7ac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the current working directory\n",
    "script_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9be5bde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_sentences = []\n",
    "\n",
    "\n",
    "def split_insert_text_by_delta(action, prev_action, threshold=5):\n",
    "    \"\"\"\n",
    "    Splits an 'insert_text' action into AI and human based on insert length from delta.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ops = action[\"action_logs\"][0][\"textDelta\"][\"ops\"]\n",
    "        inserted_text = ops[1].get(\"insert\", \"\")\n",
    "    except (IndexError, KeyError, TypeError):\n",
    "        action[\"level_1_action_type\"] = \"insert_text_human\"\n",
    "        action[\"human_sentences_temporal_order\"] = \" \".join(\n",
    "            action[\"sentences_temporal_order\"]\n",
    "        )\n",
    "        return [action]\n",
    "\n",
    "    if prev_action[\"level_1_action_type\"] == \"present_suggestion\" and len(inserted_text.strip()) >= threshold:\n",
    "        # ---- AI action ----\n",
    "        ai_action = action.copy()\n",
    "        ai_action[\"action_logs\"] = ai_action[\"action_logs\"][0]\n",
    "        ai_action[\"action_delta\"] = [\n",
    "            \"INSERT\",\n",
    "            inserted_text,\n",
    "            action[\"action_delta\"][2],\n",
    "            action[\"action_delta\"][3],\n",
    "        ]\n",
    "        ai_action[\"action_modified_sentences\"] = utils.sent_tokenize(inserted_text)\n",
    "        ai_sentences.extend(ai_action[\"action_modified_sentences\"])\n",
    "        ai_action[\"action_end_writing\"] = (\n",
    "            ai_action[\"action_start_writing\"] + inserted_text\n",
    "        )\n",
    "        ai_action[\"level_1_action_type\"] = \"insert_text_ai\"\n",
    "\n",
    "        # ---- Human action ----\n",
    "        action_human = action.copy()\n",
    "        action_human[\"action_start_writing\"] = ai_action[\"action_end_writing\"]\n",
    "        remaining_text = action_human[\"action_end_writing\"][\n",
    "            len(action_human[\"action_start_writing\"]) :\n",
    "        ]\n",
    "        action_human[\"action_delta\"] = [\n",
    "            \"INSERT\",\n",
    "            remaining_text,\n",
    "            action[\"action_delta\"][2],\n",
    "            action[\"action_delta\"][3],\n",
    "        ]\n",
    "        action_human[\"action_logs\"] = action_human[\"action_logs\"][1:]\n",
    "        action_human[\"level_1_action_type\"] = \"insert_text_human\"\n",
    "\n",
    "        # ---- Filter modified sentences ----\n",
    "        action_human[\"action_modified_sentences\"] = [\n",
    "            s\n",
    "            for s in action_human[\"action_modified_sentences\"]\n",
    "            if not any(\n",
    "                are_strings_similar_lev(s, ai_s)\n",
    "                for ai_s in ai_action[\"action_modified_sentences\"]\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # ---- Filter temporal order ----\n",
    "        sentences_human = [\n",
    "            s\n",
    "            for s in action_human[\"sentences_temporal_order\"]\n",
    "            if s.count(\"$\") < 2 and not any(\n",
    "                are_strings_similar_lev(s, ai_s)\n",
    "                for ai_s in ai_action[\"action_modified_sentences\"]\n",
    "            )\n",
    "        ]\n",
    "        action_human[\"human_sentences_temporal_order\"] = \" \".join(sentences_human)\n",
    "\n",
    "        sentences_without_prompts = [\n",
    "            s\n",
    "            for s in action_human[\"sentences_temporal_order\"]\n",
    "            if (\n",
    "                s.count(\"$\") < 2\n",
    "            )\n",
    "        ]\n",
    "        action_human[\"sentences_temporal_order_without_prompts\"] = sentences_without_prompts\n",
    "        ai_action[\"sentences_temporal_order_without_prompts\"] = sentences_without_prompts\n",
    "        \n",
    "        return [ai_action, action_human]\n",
    "\n",
    "    else:\n",
    "        # ---- Purely human insert ----\n",
    "        action_human = action.copy()\n",
    "        action_human[\"level_1_action_type\"] = \"insert_text_human\"\n",
    "\n",
    "        sentences_human = [\n",
    "            s\n",
    "            for s in action_human[\"sentences_temporal_order\"]\n",
    "            if not any(are_strings_similar_lev(s, ai_s) for ai_s in ai_sentences)\n",
    "        ]\n",
    "        action_human[\"human_sentences_temporal_order\"] = \" \".join(sentences_human)\n",
    "\n",
    "        sentences_without_prompts = [\n",
    "            s for s in action_human[\"sentences_temporal_order\"] if (s.count(\"$\") < 2)\n",
    "        ]\n",
    "        action_human[\"sentences_temporal_order_without_prompts\"] = (\n",
    "            sentences_without_prompts\n",
    "        )\n",
    "\n",
    "        return [action_human]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88891002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing Level 1 Actions:   0%|          | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: {'eventName': 'NEXT_CLICKED', 'eventSource': 'user', 'eventTimestamp': 1752768728425}\n",
      "NEXT_CLICKED\n",
      "Error: {'eventName': 'NEXT_CLICKED', 'eventSource': 'user', 'eventTimestamp': 1752768728425}\n",
      "NEXT_CLICKED\n",
      "Error: {'eventName': 'NEXT_CLICKED', 'eventSource': 'user', 'eventTimestamp': 1752783091396}\n",
      "NEXT_CLICKED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing Level 1 Actions:  14%|█▍        | 2/14 [00:00<00:01, 11.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: {'eventName': 'NEXT_CLICKED', 'eventSource': 'user', 'eventTimestamp': 1752783091396}\n",
      "NEXT_CLICKED\n",
      "Error: {'eventName': 'NEXT_CLICKED', 'eventSource': 'user', 'eventTimestamp': 1752797464057}\n",
      "NEXT_CLICKED\n",
      "Error: {'eventName': 'NEXT_CLICKED', 'eventSource': 'user', 'eventTimestamp': 1752797464057}\n",
      "NEXT_CLICKED\n",
      "Error: {'eventName': 'NEXT_CLICKED', 'eventSource': 'user', 'eventTimestamp': 1752862294085}\n",
      "NEXT_CLICKED\n",
      "Error: {'eventName': 'NEXT_CLICKED', 'eventSource': 'user', 'eventTimestamp': 1752862294085}\n",
      "NEXT_CLICKED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing Level 1 Actions:  29%|██▊       | 4/14 [00:00<00:00, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: {'eventName': 'NEXT_CLICKED', 'eventSource': 'user', 'eventTimestamp': 1753050258907}\n",
      "NEXT_CLICKED\n",
      "Error: {'eventName': 'NEXT_CLICKED', 'eventSource': 'user', 'eventTimestamp': 1753050258907}\n",
      "NEXT_CLICKED\n",
      "Error: {'eventName': 'NEXT_CLICKED', 'eventSource': 'user', 'eventTimestamp': 1753211326951}\n",
      "NEXT_CLICKED\n",
      "Error: {'eventName': 'NEXT_CLICKED', 'eventSource': 'user', 'eventTimestamp': 1753211326951}\n",
      "NEXT_CLICKED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing Level 1 Actions:  43%|████▎     | 6/14 [00:00<00:00,  8.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: {'eventName': 'NEXT_CLICKED', 'eventSource': 'user', 'eventTimestamp': 1752775741979}\n",
      "NEXT_CLICKED\n",
      "Error: {'eventName': 'NEXT_CLICKED', 'eventSource': 'user', 'eventTimestamp': 1752775741979}\n",
      "NEXT_CLICKED\n",
      "Error: {'eventName': 'NEXT_CLICKED', 'eventSource': 'user', 'eventTimestamp': 1752855918299}\n",
      "NEXT_CLICKED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing Level 1 Actions:  57%|█████▋    | 8/14 [00:00<00:00,  9.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: {'eventName': 'NEXT_CLICKED', 'eventSource': 'user', 'eventTimestamp': 1752855918299}\n",
      "NEXT_CLICKED\n",
      "Error: {'eventName': 'NEXT_CLICKED', 'eventSource': 'user', 'eventTimestamp': 1753017123863}\n",
      "NEXT_CLICKED\n",
      "Error: {'eventName': 'NEXT_CLICKED', 'eventSource': 'user', 'eventTimestamp': 1753017123863}\n",
      "NEXT_CLICKED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing Level 1 Actions:  71%|███████▏  | 10/14 [00:00<00:00, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: {'eventName': 'NEXT_CLICKED', 'eventSource': 'user', 'eventTimestamp': 1753060358599}\n",
      "NEXT_CLICKED\n",
      "Error: {'eventName': 'NEXT_CLICKED', 'eventSource': 'user', 'eventTimestamp': 1753060358599}\n",
      "NEXT_CLICKED\n",
      "Error: {'eventName': 'NEXT_CLICKED', 'eventSource': 'user', 'eventTimestamp': 1753112478228}\n",
      "NEXT_CLICKED\n",
      "Error: {'eventName': 'NEXT_CLICKED', 'eventSource': 'user', 'eventTimestamp': 1753112478228}\n",
      "NEXT_CLICKED\n",
      "Error: {'eventName': 'NEXT_CLICKED', 'eventSource': 'user', 'eventTimestamp': 1753913882361}\n",
      "NEXT_CLICKED\n",
      "Error: {'eventName': 'NEXT_CLICKED', 'eventSource': 'user', 'eventTimestamp': 1753913882361}\n",
      "NEXT_CLICKED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing Level 1 Actions:  86%|████████▌ | 12/14 [00:01<00:00, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: {'eventName': 'NEXT_CLICKED', 'eventSource': 'user', 'eventTimestamp': 1753972753614}\n",
      "NEXT_CLICKED\n",
      "Error: {'eventName': 'NEXT_CLICKED', 'eventSource': 'user', 'eventTimestamp': 1753972753614}\n",
      "NEXT_CLICKED\n",
      "Error: {'eventName': 'NEXT_CLICKED', 'eventSource': 'user', 'eventTimestamp': 1754059083586}\n",
      "NEXT_CLICKED\n",
      "Error: {'eventName': 'NEXT_CLICKED', 'eventSource': 'user', 'eventTimestamp': 1754059083586}\n",
      "NEXT_CLICKED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing Level 1 Actions: 100%|██████████| 14/14 [00:01<00:00,  9.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary to store parsed actions\n",
    "level_1_actions_per_session = {}\n",
    "\n",
    "# Iterate through all sessions in the raw logs and parse actions\n",
    "for session in tqdm(logs_by_session, desc=\"Parsing Level 1 Actions\"):\n",
    "\n",
    "    # Initialize the MergeActionsAnalyzer for each session\n",
    "    actions_analyzer = action_parser.MergeActionsAnalyzer(\n",
    "        last_action=None,\n",
    "        raw_logs=logs_by_session[session]\n",
    "    )\n",
    "\n",
    "    # Parse the logs for the session into structured actions\n",
    "    actions_lst, last_action = actions_analyzer.parse_actions_from_logs(\n",
    "        all_logs=logs_by_session[session],\n",
    "        last_action=None,\n",
    "        DLT_CHAR_MAX_COUNT=9  # Optional: Specify tiny delete threshold here\n",
    "    )\n",
    "\n",
    "    # Store the parsed actions in the output dictionary\n",
    "    level_1_actions_per_session[session] = actions_lst\n",
    "\n",
    "# Add a new key to each action for classification and further analysis\n",
    "for session_key, actions in level_1_actions_per_session.items():\n",
    "    i = 0\n",
    "\n",
    "    while i < len(actions):\n",
    "        action = actions[i]\n",
    "        if i>0 and \"action_type\" in action and action[\"action_type\"] == \"insert_text\":\n",
    "            split_actions = split_insert_text_by_delta(action, actions[i-1])\n",
    "            if len(split_actions) == 1:\n",
    "                actions[i] = split_actions[0]\n",
    "                i += 1\n",
    "            else:\n",
    "                actions[i:i+1] = split_actions\n",
    "                i += len(split_actions)\n",
    "        else:\n",
    "            if not \"action_type\" in action:\n",
    "                action[\"level_1_action_type\"] = \"NEXT_CLICKED\"\n",
    "            else:\n",
    "                action[\"level_1_action_type\"] = action[\"action_type\"]\n",
    "            i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
